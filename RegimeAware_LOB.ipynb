{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56df3dc2",
   "metadata": {},
   "source": "# Regime-Aware Limit Order Book Analysis\n\n## Overview\n\nThis notebook implements a regime-aware machine learning approach to predict short-horizon mid-price direction in cryptocurrency limit order books (LOB). The core hypothesis is that **market predictability is regime-dependent**: predictive signals are stronger during \"toxic\" market conditions (high order imbalance, aggressive cancellations) compared to \"balanced\" conditions.\n\n## Pipeline\n\n1. **Data Loading**: High-frequency BTC LOB data (1-second snapshots)\n2. **Feature Engineering**: Order book depth, imbalances, market/cancel flows, realized volatility\n3. **Label Creation**: Ternary classification (Up/Down/Flat) based on 30-second forward returns\n4. **Regime Discovery**: Hidden Markov Model (HMM) to identify toxic vs. balanced market states\n5. **Supervised Learning**: Logistic Regression and XGBoost with regime-aware features\n6. **Walk-Forward Validation**: Time-series cross-validation with 9 folds\n7. **Evaluation**: Regime-conditioned hit rates to validate hypothesis\n\n## Key Hypothesis\n\n**Toxic regimes** (characterized by large order imbalances and aggressive cancellation activity) should exhibit higher predictability than **balanced regimes** (symmetric order flow and stable depth). We measure this via \"lift\" = Hit Rate(toxic) - Hit Rate(balanced)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c604c",
   "metadata": {},
   "outputs": [],
   "source": "import warnings, os, sys, math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings(\"ignore\")\n\n# Core ML libraries\nfrom hmmlearn.hmm import GaussianHMM\nfrom xgboost import XGBClassifier\n\n# Try to import LightGBM (optional)\ntry:\n    from lightgbm import LGBMClassifier\n    LGBM_AVAILABLE = True\nexcept ImportError:\n    LGBM_AVAILABLE = False\n    print(\"⚠ LightGBM not available. Install with: pip install lightgbm\")\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils.class_weight import compute_sample_weight\nfrom sklearn.metrics import accuracy_score, f1_score\n\nprint(\"✓ All required libraries loaded successfully\")\nprint(f\"✓ LightGBM available: {LGBM_AVAILABLE}\")"
  },
  {
   "cell_type": "markdown",
   "id": "c7a34f6b",
   "metadata": {},
   "source": "## 0. Configuration Parameters\n\nThis section defines all hyperparameters and settings for the pipeline. These values have been tuned for optimal performance on the BTC LOB dataset."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5495c4",
   "metadata": {},
   "outputs": [],
   "source": "# ===================================================================\n# DATA & COLUMN CONFIGURATION\n# ===================================================================\nDATA_CSV = 'BTC_1sec.csv'  # High-frequency BTC LOB data from Kaggle\n\nTIME_COL   = 'timestamp'   # Timestamp column name\nMID_COL    = 'midpoint'    # Mid-price (average of best bid and ask)\nSPREAD_COL = 'spread'      # Bid-ask spread\n\nTOP_K = 15  # Number of order book levels to aggregate (depth)\n\n# ===================================================================\n# LABEL CREATION (BINARY CLASSIFICATION)\n# ===================================================================\nHORIZON_SEC = 30    # Prediction horizon in seconds (30s forward return)\n\n# Threshold for up/down classification (basis points)\n# BINARY classification: only predict UP vs DOWN (ignore small moves)\nTHRESH_BPS = 2.0    # 2 bp = 0.02% (moves smaller than this are filtered out)\n\n# ===================================================================\n# WALK-FORWARD VALIDATION\n# ===================================================================\nTRAIN_DAYS  = 3     # Days of historical data for training\nTEST_HOURS  = 4     # Hours of data for testing per fold\nEMBARGO_SEC = 60    # Embargo period between train and test (prevents leakage)\nSTRIDE_HRS  = 12    # Hours between consecutive folds (12hr = 9 folds total)\n\n# ===================================================================\n# PCA DIMENSIONALITY REDUCTION\n# ===================================================================\nUSE_PCA = True       # Enable PCA for feature compression\nPCA_VARIANCE = 0.95  # Retain 95% of variance (reduces 26 features to ~12-15 components)\n\n# ===================================================================\n# MODEL HYPERPARAMETERS\n# ===================================================================\nMAX_TRAIN_SAMPLES = 200000  # INCREASED from 120K for better model training\n\n# HMM (Hidden Markov Model) for regime discovery (2 states: balanced vs toxic)\nHMM_COVARIANCE = 'diag'     # Diagonal covariance (faster than 'full', works well in practice)\nHMM_ITERATIONS = 150        # EM algorithm iterations (more = better convergence but slower)\n\n# XGBoost (Gradient Boosting) for supervised prediction\nXGB_N_ESTIMATORS = 300      # Number of boosting rounds\nXGB_MAX_DEPTH = 6           # Maximum tree depth (controls model complexity)\nXGB_LEARNING_RATE = 0.05    # Step size shrinkage (lower = more conservative, better generalization)\nXGB_EARLY_STOPPING = 30     # Stop if validation score doesn't improve for 30 rounds\n\n# ===================================================================\n# REPRODUCIBILITY\n# ===================================================================\nRANDOM_STATE = 42\nnp.random.seed(RANDOM_STATE)"
  },
  {
   "cell_type": "markdown",
   "id": "d2d5b450",
   "metadata": {},
   "source": "## 1. Data Loading & Inspection\n\n**Dataset**: High-frequency cryptocurrency LOB data from Kaggle ([link](https://www.kaggle.com/datasets/martinsn/high-frequency-crypto-limit-order-book-data))\n\nThe dataset contains 1-second snapshots of the Bitcoin limit order book with:\n- **Timestamp**: System time for each snapshot\n- **Midpoint**: (Best Bid + Best Ask) / 2\n- **Spread**: Best Ask - Best Bid\n- **Depth**: Notional values at each price level (bids/asks)\n- **Flows**: Market orders, limit orders, and cancellations at each level\n\nWe load the data, standardize timestamps to UTC, and sort chronologically."
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e37ed59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1030728\n",
      "Time range: 2021-04-07 11:32:42.122161+00:00 → 2021-04-19 09:54:22.386544+00:00\n",
      "Columns: ['Unnamed: 0', 'system_time', 'midpoint', 'spread', 'buys', 'sells', 'bids_distance_0', 'bids_distance_1', 'bids_distance_2', 'bids_distance_3', 'bids_distance_4', 'bids_distance_5'] ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "# Basic normalization of time column\n",
    "if TIME_COL not in df.columns:\n",
    "    for c in df.columns:\n",
    "        if 'time' in c.lower():\n",
    "            TIME_COL = c\n",
    "            break\n",
    "\n",
    "df[TIME_COL] = pd.to_datetime(df[TIME_COL], utc=True, errors='coerce')\n",
    "df = df.dropna(subset=[TIME_COL]).sort_values(TIME_COL).reset_index(drop=True)\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Time range:\", df[TIME_COL].min(), \"→\", df[TIME_COL].max())\n",
    "print(\"Columns:\", list(df.columns)[:12], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501c400",
   "metadata": {},
   "source": "## 2. Feature Engineering\n\nWe construct **26 microstructure features** from the raw LOB data, organized into 5 categories:\n\n### Original Features (11):\n1. **spread_pct**: Relative spread (spread / midpoint) - liquidity cost\n2. **BidDepth_k / AskDepth_k**: Total notional depth across top K levels\n3. **DepthImb_k**: Order book skew (bid-ask depth imbalance)\n4. **MO_bid_tau / MO_ask_tau**: Market order notional (aggressive flow)\n5. **MO_imb_tau**: Market order imbalance (buying vs selling pressure)\n6. **CA_bid_tau / CA_ask_tau**: Cancellation notional (strategic removals)\n7. **CA_imb_tau**: Cancel imbalance (toxicity signal)\n8. **rv_5s**: Realized volatility (5-second rolling std of returns)\n\n### New Features for Accuracy Boost (15):\n\n**Momentum Features (5):**\n- **ret_5s, ret_10s, ret_30s, ret_60s**: Multi-timeframe returns (trend direction)\n- **ret_accel**: Price acceleration (momentum of momentum)\n\n**Volatility Features (3):**\n- **rv_30s**: 30-second realized volatility\n- **rv_ratio**: Short-term vs long-term volatility ratio (detects regime changes)\n- **hl_range_10s**: High-low range as % of midpoint (price variability)\n\n**Flow Momentum (3):**\n- **MO_imb_chg**: Change in market order imbalance (flow acceleration)\n- **CA_imb_chg**: Change in cancel imbalance (toxicity acceleration)\n- **Depth_imb_chg**: Change in depth imbalance (book shift dynamics)\n\n**Order Book Shape (2):**\n- **depth_concentration**: Top 3 levels / Total depth (liquidity distribution)\n- **total_depth**: Log of total depth (overall liquidity level)\n\n**Temporal Features (2):**\n- **hour_sin / hour_cos**: Cyclical hour encoding (intraday patterns)\n\n### Rationale:\n- **Momentum**: Captures trend and mean-reversion signals\n- **Volatility**: Different regimes have different volatility profiles\n- **Flow changes**: Acceleration matters more than absolute levels\n- **Shape**: Concentrated vs dispersed liquidity affects predictability\n- **Temporal**: Crypto markets have hour-of-day effects (Asian/European/US trading hours)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5668c0",
   "metadata": {},
   "outputs": [],
   "source": "def level_cols(prefix, k=TOP_K, in_df=None):\n    cols = [f\"{prefix}_{i}\" for i in range(k)]\n    if in_df is not None:\n        cols = [c for c in cols if c in in_df.columns]\n    return cols\n\ndef agg_levels(df, prefix, k=TOP_K):\n    cols = level_cols(prefix, k, in_df=df)\n    if not cols:\n        return pd.Series(0.0, index=df.index)\n    return df[cols].sum(axis=1)\n\n# ============================================================================\n# ORIGINAL FEATURES (11 features)\n# ============================================================================\n\n# Spread\ndf['spread_pct'] = (df[SPREAD_COL] / df[MID_COL]).replace([np.inf, -np.inf], np.nan).fillna(0)\n\n# Depth features\ndf['BidDepth_k'] = agg_levels(df, \"bids_limit_notional\", TOP_K)\ndf['AskDepth_k'] = agg_levels(df, \"asks_limit_notional\", TOP_K)\ndf['DepthImb_k'] = (df['BidDepth_k'] - df['AskDepth_k']) / (df['BidDepth_k'] + df['AskDepth_k'] + 1e-9)\n\n# Market order flows\ndf['MO_bid_tau'] = agg_levels(df, \"bids_market_notional\", TOP_K)\ndf['MO_ask_tau'] = agg_levels(df, \"asks_market_notional\", TOP_K)\ndf['MO_imb_tau'] = (df['MO_ask_tau'] - df['MO_bid_tau']) / (df['MO_ask_tau'] + df['MO_bid_tau'] + 1e-9)\n\n# Cancel flows\ndf['CA_bid_tau'] = agg_levels(df, \"bids_cancel_notional\", TOP_K)\ndf['CA_ask_tau'] = agg_levels(df, \"asks_cancel_notional\", TOP_K)\ndf['CA_imb_tau'] = (df['CA_ask_tau'] - df['CA_bid_tau']) / (df['CA_ask_tau'] + df['CA_bid_tau'] + 1e-9)\n\n# Realized volatility\nret = df[MID_COL].pct_change()\ndf['rv_5s'] = ret.rolling(5, min_periods=1).std().fillna(0)\n\n# ============================================================================\n# NEW FEATURES FOR ACCURACY BOOST (15 additional features)\n# ============================================================================\n\nprint(\"Engineering additional features for improved accuracy...\")\n\n# --- 1. MOMENTUM FEATURES (5 features) ---\n# Multi-timeframe returns capture trend direction\ndf['ret_5s'] = df[MID_COL].pct_change(5).fillna(0)\ndf['ret_10s'] = df[MID_COL].pct_change(10).fillna(0)\ndf['ret_30s'] = df[MID_COL].pct_change(30).fillna(0)\ndf['ret_60s'] = df[MID_COL].pct_change(60).fillna(0)\n\n# Price acceleration (second derivative of price)\ndf['ret_accel'] = df['ret_5s'] - df['ret_5s'].shift(5).fillna(0)\n\n# --- 2. VOLATILITY FEATURES (3 features) ---\n# Volatility ratios capture regime shifts\ndf['rv_30s'] = ret.rolling(30, min_periods=1).std().fillna(0)\ndf['rv_ratio'] = (df['rv_5s'] / (df['rv_30s'] + 1e-9)).replace([np.inf, -np.inf], 0).fillna(0)\n\n# High-low range (price variability)\ndf['hl_range_10s'] = df[MID_COL].rolling(10).max() - df[MID_COL].rolling(10).min()\ndf['hl_range_10s'] = (df['hl_range_10s'] / df[MID_COL]).fillna(0)\n\n# --- 3. FLOW MOMENTUM (3 features) ---\n# Changes in imbalances indicate flow acceleration\ndf['MO_imb_chg'] = df['MO_imb_tau'] - df['MO_imb_tau'].shift(5).fillna(0)\ndf['CA_imb_chg'] = df['CA_imb_tau'] - df['CA_imb_tau'].shift(5).fillna(0)\ndf['Depth_imb_chg'] = df['DepthImb_k'] - df['DepthImb_k'].shift(5).fillna(0)\n\n# --- 4. ORDER BOOK SHAPE (2 features) ---\n# Depth concentration: how much liquidity is in top levels vs deeper levels\ntop3_bid = agg_levels(df, \"bids_limit_notional\", 3)\ntop3_ask = agg_levels(df, \"asks_limit_notional\", 3)\ndf['depth_concentration'] = ((top3_bid + top3_ask) / (df['BidDepth_k'] + df['AskDepth_k'] + 1e-9)).fillna(0)\n\n# Total depth (proxy for liquidity)\ndf['total_depth'] = np.log1p(df['BidDepth_k'] + df['AskDepth_k'])\n\n# --- 5. TEMPORAL FEATURES (2 features) ---\n# Crypto markets have intraday patterns\ndf['hour'] = pd.to_datetime(df[TIME_COL]).dt.hour\ndf['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)  # Cyclical encoding\ndf['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n\n# Drop temporary column\ndf = df.drop('hour', axis=1)\n\n# ============================================================================\n# FEATURE LIST (26 total features: 11 original + 15 new)\n# ============================================================================\n\nfeature_cols = [\n    # Original features (11)\n    'spread_pct', 'DepthImb_k', 'MO_imb_tau', 'CA_imb_tau', 'rv_5s',\n    'BidDepth_k', 'AskDepth_k', 'MO_bid_tau', 'MO_ask_tau', 'CA_bid_tau', 'CA_ask_tau',\n    \n    # Momentum features (5)\n    'ret_5s', 'ret_10s', 'ret_30s', 'ret_60s', 'ret_accel',\n    \n    # Volatility features (3)\n    'rv_30s', 'rv_ratio', 'hl_range_10s',\n    \n    # Flow momentum (3)\n    'MO_imb_chg', 'CA_imb_chg', 'Depth_imb_chg',\n    \n    # Order book shape (2)\n    'depth_concentration', 'total_depth',\n    \n    # Temporal features (2)\n    'hour_sin', 'hour_cos'\n]\n\nprint(f\"\\nTotal features: {len(feature_cols)}\")\nprint(\"\\nFeature existence check:\")\nprint(pd.DataFrame({'exists': [c in df.columns for c in feature_cols]}, index=feature_cols))"
  },
  {
   "cell_type": "markdown",
   "id": "131d1e00",
   "metadata": {},
   "source": "## 3. Label Creation (Binary Classification: Up vs Down)\n\nWe create **binary classification labels** based on the **forward 30-second mid-price return**.\n\n### Binary Classification:\n- **y = +1** (UP): if (mid_t+30s - mid_t) / mid_t > THRESH_BPS\n- **y = -1** (DOWN): if (mid_t+30s - mid_t) / mid_t < -THRESH_BPS\n- **Samples with |return| < THRESH_BPS are FILTERED OUT** (too small to predict reliably)\n\n### Why Binary (not Ternary)?\n- **Simpler problem:** Up vs Down is easier than Up/Down/Flat\n- **Higher accuracy expected:** 50% random baseline → easier to beat than 33.3%\n- **More practical:** Trading strategies care about direction, not \"flat\"\n- **Cleaner signals:** Removes noisy near-zero returns\n\n### Threshold: THRESH_BPS = {THRESH_BPS}bp\n- Filters out microstructure noise\n- Only keeps economically meaningful moves\n- Higher threshold = fewer but cleaner labels\n\n### Label Distribution:\nWe expect roughly balanced up/down labels (close to 50/50)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfefc85",
   "metadata": {},
   "outputs": [],
   "source": "df = df.sort_values(TIME_COL).reset_index(drop=True)\napprox_dt = (df[TIME_COL].iloc[1] - df[TIME_COL].iloc[0]).total_seconds()\nshift_n = max(1, int(round(HORIZON_SEC / max(1, approx_dt))))\ndf['mid_fwd'] = df[MID_COL].shift(-shift_n)\n\nthresh = THRESH_BPS * 1e-4\nr = (df['mid_fwd'] - df[MID_COL]) / df[MID_COL]\n\n# Binary classification: +1 for up, -1 for down, NaN for small moves\ny = np.where(r > thresh, 1, np.where(r < -thresh, -1, np.nan))\ndf['y'] = y\n\n# Filter out small moves (keep only clear up/down)\ndf_lbl = df.dropna(subset=['mid_fwd', 'y']).copy()\n\n# Check label distribution\nlabel_counts = df_lbl['y'].value_counts(normalize=True).to_dict()\nprint(f\"Label distribution (binary): {label_counts}\")\nprint(f\"Up samples:   {label_counts.get(1.0, 0):.1%}\")\nprint(f\"Down samples: {label_counts.get(-1.0, 0):.1%}\")\nprint(f\"Total samples after filtering: {len(df_lbl):,} (removed {len(df) - len(df_lbl):,} small moves)\")"
  },
  {
   "cell_type": "markdown",
   "id": "983e642a",
   "metadata": {},
   "source": "## 4. Feature Scaling & PCA\n\n### Standardization\nAll features are z-scored (mean=0, std=1) using `StandardScaler`. This is critical because:\n- Features have different scales (e.g., spread_pct ~ 0.001, BidDepth_k ~ 100,000)\n- ML algorithms (especially Logistic Regression and HMM) are sensitive to scale\n\n**Important**: We fit the scaler on training data only, then transform both train and test. This prevents data leakage.\n\n### PCA (Principal Component Analysis)\nWe apply PCA to reduce dimensionality from **26 features** to ~**12-15 components** while retaining 95% of variance. Benefits:\n- **Reduces noise**: Minor components often contain noise rather than signal\n- **Improves generalization**: Fewer parameters reduce overfitting risk\n- **Faster training**: Especially important for HMM (O(n² components))\n- **Removes multicollinearity**: Our 26 features are correlated; PCA creates independent components\n\n**Note**: PCA is fit on training data only to prevent leakage."
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81773e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_features(df_train, df_test, cols=None, use_pca=USE_PCA, pca_var=PCA_VARIANCE):\n",
    "    if cols is None:\n",
    "        cols = feature_cols\n",
    "    scaler = StandardScaler()\n",
    "    Xtr = scaler.fit_transform(df_train[cols].fillna(0.0).values)\n",
    "    Xte = scaler.transform(df_test[cols].fillna(0.0).values)\n",
    "    \n",
    "    pca = None\n",
    "    if use_pca:\n",
    "        pca = PCA(n_components=pca_var, random_state=RANDOM_STATE)\n",
    "        Xtr = pca.fit_transform(Xtr)\n",
    "        Xte = pca.transform(Xte)\n",
    "    \n",
    "    return Xtr, Xte, pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6c65b",
   "metadata": {},
   "source": "## 5. Walk-Forward Time-Series Cross-Validation\n\n### Why Walk-Forward?\nStandard k-fold CV shuffles data randomly, which **leaks future information** in time-series contexts. Walk-forward validation simulates real trading:\n- Train on past data only\n- Test on strictly future data\n- Embargo period prevents train/test overlap\n\n### Configuration:\n- **Training window**: 3 days of historical data\n- **Test window**: 4 hours of future data\n- **Embargo**: 60 seconds gap between train and test sets\n- **Stride**: 12 hours between folds (creates 9 overlapping folds)\n\n### Why 60s embargo?\nPrevents near-term autocorrelation from contaminating test set. In high-frequency data, observations 1 second apart are highly correlated.\n\n### Fold Structure:\n```\nFold 0: Train [Day 0-3] → Test [Day 3 + 60s to Day 3 + 4hr]\nFold 1: Train [Day 0.5-3.5] → Test [Day 3.5 + 60s to Day 3.5 + 4hr]\n...\n```"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24288f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def walk_forward_splits_hours_v2(\n",
    "    timestamps, train_days=3, test_hours=4, embargo_sec=60, stride_hours=None\n",
    "):\n",
    "    ts = pd.to_datetime(timestamps, utc=True).sort_values()\n",
    "    tmin = ts.min()\n",
    "    tmax = ts.max()\n",
    "    stride = pd.Timedelta(hours=(stride_hours or test_hours))\n",
    "\n",
    "    cur = tmin\n",
    "    while True:\n",
    "        tr_s = cur\n",
    "        tr_e = tr_s + pd.Timedelta(days=train_days)\n",
    "        te_s = tr_e + pd.Timedelta(seconds=embargo_sec)\n",
    "        te_e = te_s + pd.Timedelta(hours=test_hours)\n",
    "        if te_e > tmax:\n",
    "            break\n",
    "        yield (tr_s, tr_e, te_s, te_e)\n",
    "        cur = cur + stride\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26851818",
   "metadata": {},
   "source": "## 6. Regime Discovery via Hidden Markov Model (HMM)\n\n### Unsupervised Learning: Identifying Market Regimes\n\nWe use a **2-state Gaussian HMM** to discover latent market regimes from the PCA-transformed features. The HMM models:\n- **Hidden states**: Latent regime variable (balanced vs. toxic)\n- **Emissions**: Observed features (PCA components)\n- **Transitions**: Regime persistence and switching dynamics\n\n### Why HMM instead of K-Means?\n- **Temporal dynamics**: HMM captures regime persistence (toxic periods cluster in time)\n- **Probabilistic**: Soft assignments rather than hard clusters\n- **Markov property**: Current state depends on previous state (realistic for markets)\n\n### Identifying the \"Toxic\" State\nAfter fitting the HMM, we label states by computing a **toxicity score** for each state:\n```\ntoxicity_score = |MO_imb_tau| + |CA_imb_tau| + |DepthImb_k|\n```\n\nThe state with **higher average toxicity score** is labeled as the \"toxic\" regime.\n\n### Hyperparameters:\n- **n_components=2**: Binary regime (balanced vs. toxic)\n- **covariance_type='diag'**: Assumes feature independence (faster, works well in practice)\n- **n_iter=150**: EM algorithm iterations for convergence"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9b83af",
   "metadata": {},
   "outputs": [],
   "source": "def fit_hmm(X_train, df_train, n_states=2, random_state=42):\n    \"\"\"\n    Fit a Gaussian HMM to discover market regimes and identify the toxic state.\n    \n    Parameters:\n    -----------\n    X_train : array-like, shape (n_samples, n_features)\n        Scaled and PCA-transformed features\n    df_train : DataFrame\n        Original training data (needed for toxicity score calculation)\n    n_states : int\n        Number of hidden states (default=2 for balanced/toxic)\n    random_state : int\n        Random seed for reproducibility\n        \n    Returns:\n    --------\n    hmm : GaussianHMM\n        Fitted HMM model\n    tox_state : int\n        Index of the state identified as \"toxic\" (0 or 1)\n    \"\"\"\n    # Compute toxicity score for each sample\n    tox_score_cols = ['MO_imb_tau', 'CA_imb_tau', 'DepthImb_k']\n    train_score = df_train[tox_score_cols].fillna(0).copy()\n    train_score['tox_score'] = (\n        train_score['MO_imb_tau'].abs() +\n        train_score['CA_imb_tau'].abs() +\n        train_score['DepthImb_k'].abs()\n    )\n    \n    # Fit HMM on PCA-transformed features\n    hmm = GaussianHMM(\n        n_components=n_states,\n        covariance_type=HMM_COVARIANCE,\n        n_iter=HMM_ITERATIONS,\n        random_state=random_state\n    )\n    \n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", message=\"Model is not converging\")\n        hmm.fit(X_train)\n    \n    # Predict states and compute average toxicity score per state\n    states = hmm.predict(X_train)\n    state_toxicity = pd.DataFrame({\n        'state': states,\n        'tox': train_score['tox_score'].values\n    }).groupby('state')['tox'].mean()\n    \n    # Identify toxic state as the one with higher average toxicity\n    tox_state = int(state_toxicity.idxmax())\n    \n    return hmm, tox_state"
  },
  {
   "cell_type": "markdown",
   "id": "67126975",
   "metadata": {},
   "source": "## 7. Supervised Learning: Baseline vs. Regime-Aware Models\n\nWe train **four models** per fold to evaluate the regime-awareness hypothesis:\n\n### Baseline Models (no regime information):\n1. **Logistic Regression**: Linear model, fast, interpretable\n2. **XGBoost**: Gradient-boosted trees, captures non-linearities\n\n### Regime-Aware Models (with HMM regime as feature):\n3. **Logistic Regression + Regime**: LR with regime binary feature added\n4. **XGBoost + Regime**: XGBoost with regime binary feature added\n\n### Model Configuration:\n- **Class balancing**: `class_weight='balanced'` and sample weights to handle class imbalance\n- **Early stopping**: XGBoost stops if validation score plateaus for 30 rounds\n- **Probabilistic outputs**: All models produce P(up), P(down), P(flat)\n\n### Hypothesis Testing:\nIf regime-awareness helps, we expect:\n- **Regime-aware XGBoost** > **Baseline XGBoost** (overall accuracy)\n- **Hit Rate in toxic regime** > **Hit Rate in balanced regime** (regime-conditioned performance)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da9079",
   "metadata": {},
   "outputs": [],
   "source": "# Binary classification: -1 (down) and +1 (up)\nCLASSES = [-1, 1]\nENC_MAP = {-1: 0, 1: 1}  # Encode to 0/1 for sklearn\nDEC_MAP = {v: k for k, v in ENC_MAP.items()}\n\ndef metrics_from_proba_encoded(proba, y_true_enc):\n    \"\"\"Compute accuracy and F1 for binary classification.\"\"\"\n    yhat_enc = proba.argmax(axis=1)\n    yhat = np.array([DEC_MAP[i] for i in yhat_enc])\n    ytrue = np.array([DEC_MAP[i] for i in y_true_enc])\n    acc = accuracy_score(ytrue, yhat)\n    f1 = f1_score(ytrue, yhat, average='binary', pos_label=1)\n    return acc, f1, yhat, ytrue\n\ndef regime_hits(yhat, ytrue, regime_flag):\n    \"\"\"Compute hit rates conditioned on regime.\"\"\"\n    bal = (regime_flag == 0)\n    tox = (regime_flag == 1)\n    hr_bal = float((yhat[bal] == ytrue[bal]).mean()) if bal.any() else np.nan\n    hr_tox = float((yhat[tox] == ytrue[tox]).mean()) if tox.any() else np.nan\n    return hr_bal, hr_tox\n\ndf_sup = df_lbl.dropna(subset=['y']).copy().sort_values(TIME_COL)\nfolds = list(walk_forward_splits_hours_v2(df_sup[TIME_COL], TRAIN_DAYS, TEST_HOURS, EMBARGO_SEC, STRIDE_HRS))\nprint(\"Planned folds:\", len(folds))\nprint(f\"Binary classification: {len(CLASSES)} classes (Up vs Down)\")\nprint(f\"Random baseline: 50.0%\\n\")\nfor i, (a, b, c, d) in enumerate(folds[:5]):\n    print(f\"Fold {i}: TRAIN {a}→{b}  TEST {c}→{d}\")"
  },
  {
   "cell_type": "markdown",
   "id": "6b49e5de",
   "metadata": {},
   "source": "## 8. Walk-Forward Evaluation Loop\n\nThis section executes the complete pipeline for each fold:\n1. Split data into train/test based on time windows\n2. Scale features and apply PCA (fit on train, transform both)\n3. Train baseline models (LR and XGBoost without regime)\n4. Fit HMM to discover regimes\n5. Augment features with regime indicator\n6. Train regime-aware models (LR and XGBoost with regime)\n7. Compute metrics: accuracy, F1, regime-conditioned hit rates\n\n### Key Metrics:\n- **Accuracy**: Overall correctness (% correct predictions)\n- **F1 Score**: Harmonic mean of precision and recall (macro-averaged across 3 classes)\n- **Hit Rate (Balanced)**: Accuracy when HMM predicts balanced regime\n- **Hit Rate (Toxic)**: Accuracy when HMM predicts toxic regime\n- **Lift**: Hit Rate(toxic) - Hit Rate(balanced) — **THIS IS THE KEY METRIC**\n\n### Expected Outcome:\n**Lift > 0** validates our hypothesis that toxic regimes are more predictable."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80a9915",
   "metadata": {},
   "outputs": [],
   "source": "import time\n\nresults = []\nfold = 0\nMIN_TRAIN = 300\nMIN_TEST  = 100\n\nfor (tr_s, tr_e, te_s, te_e) in folds:\n    fold_start = time.time()\n    train = df_sup[(df_sup[TIME_COL] >= tr_s) & (df_sup[TIME_COL] < tr_e)].copy()\n    test  = df_sup[(df_sup[TIME_COL] >= te_s) & (df_sup[TIME_COL] < te_e)].copy()\n    if len(train) < MIN_TRAIN or len(test) < MIN_TEST:\n        continue\n\n    # Subsample training data if too large (computational efficiency)\n    if len(train) > MAX_TRAIN_SAMPLES:\n        train = train.sample(n=MAX_TRAIN_SAMPLES, random_state=RANDOM_STATE)\n        print(f\"\\n[Fold {fold+1}/{len(folds)}] Train: {len(train):,} samples (subsampled), Test: {len(test):,} samples\")\n    else:\n        print(f\"\\n[Fold {fold+1}/{len(folds)}] Train: {len(train):,} samples, Test: {len(test):,} samples\")\n    \n    # Step 1: Scale features and apply PCA\n    t0 = time.time()\n    Xtr_base, Xte_base, pca_model = scale_features(train, test)\n    if USE_PCA and pca_model is not None and fold == 0:\n        n_components = pca_model.n_components_\n        print(f\"PCA: {len(feature_cols)} features → {n_components} components (retained {PCA_VARIANCE*100}% variance)\")\n    print(f\"  Scaling+PCA: {time.time()-t0:.1f}s\")\n    \n    # Encode labels for sklearn (binary: 0 and 1)\n    ytr_enc = np.array([ENC_MAP[v] for v in train['y'].values])\n    yte_enc = np.array([ENC_MAP[v] for v in test['y'].values])\n\n    # Step 2: Train baseline Logistic Regression (no regime info)\n    t0 = time.time()\n    lr_base = LogisticRegression(max_iter=1000, C=0.5, class_weight='balanced', solver='lbfgs')\n    lr_base.fit(Xtr_base, ytr_enc)\n    acc_lr_base, f1_lr_base, _, _ = metrics_from_proba_encoded(lr_base.predict_proba(Xte_base), yte_enc)\n    print(f\"  LR baseline: {time.time()-t0:.1f}s\")\n\n    # Step 3: Train baseline XGBoost (no regime info) - BINARY\n    t0 = time.time()\n    w_base = compute_sample_weight(class_weight='balanced', y=ytr_enc)\n    xgb_base = XGBClassifier(\n        n_estimators=XGB_N_ESTIMATORS,\n        max_depth=XGB_MAX_DEPTH,\n        learning_rate=XGB_LEARNING_RATE,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        objective='binary:logistic',  # Changed from multi:softprob\n        tree_method='hist',\n        reg_lambda=1.0,\n        random_state=RANDOM_STATE,\n        early_stopping_rounds=XGB_EARLY_STOPPING\n    )\n    # Use 80/20 split for early stopping validation\n    split_idx = int(0.8 * len(Xtr_base))\n    xgb_base.fit(\n        Xtr_base[:split_idx], ytr_enc[:split_idx],\n        sample_weight=w_base[:split_idx],\n        eval_set=[(Xtr_base[split_idx:], ytr_enc[split_idx:])],\n        verbose=False\n    )\n    acc_xgb_base, f1_xgb_base, _, _ = metrics_from_proba_encoded(xgb_base.predict_proba(Xte_base), yte_enc)\n    print(f\"  XGB baseline: {time.time()-t0:.1f}s\")\n\n    # Step 4: Fit HMM to discover regimes\n    t0 = time.time()\n    hmm, tox_state = fit_hmm(Xtr_base, train, n_states=2)\n    print(f\"  HMM: {time.time()-t0:.1f}s\")\n    \n    # Step 5: Predict regimes for train and test\n    s_tr = hmm.predict(Xtr_base)\n    s_te = hmm.predict(Xte_base)\n\n    # Binary regime indicator: 1 = toxic, 0 = balanced\n    train['regime_hmm'] = (s_tr == tox_state).astype(int)\n    test['regime_hmm']  = (s_te == tox_state).astype(int)\n\n    # Step 6: Augment features with regime indicator\n    Xtr = np.c_[Xtr_base, train['regime_hmm'].values]\n    Xte = np.c_[Xte_base, test['regime_hmm'].values]\n\n    # Step 7: Train regime-aware Logistic Regression\n    t0 = time.time()\n    lr = LogisticRegression(max_iter=1000, C=0.5, class_weight='balanced', solver='lbfgs')\n    lr.fit(Xtr, ytr_enc)\n    acc_lr, f1_lr, yhat_lr, ytrue_lr = metrics_from_proba_encoded(lr.predict_proba(Xte), yte_enc)\n    print(f\"  LR regime-aware: {time.time()-t0:.1f}s\")\n\n    # Step 8: Train regime-aware XGBoost - BINARY\n    t0 = time.time()\n    w = compute_sample_weight(class_weight='balanced', y=ytr_enc)\n    xgb = XGBClassifier(\n        n_estimators=XGB_N_ESTIMATORS,\n        max_depth=XGB_MAX_DEPTH,\n        learning_rate=XGB_LEARNING_RATE,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        objective='binary:logistic',  # Changed from multi:softprob\n        tree_method='hist',\n        reg_lambda=1.0,\n        random_state=RANDOM_STATE,\n        early_stopping_rounds=XGB_EARLY_STOPPING\n    )\n    split_idx = int(0.8 * len(Xtr))\n    xgb.fit(\n        Xtr[:split_idx], ytr_enc[:split_idx],\n        sample_weight=w[:split_idx],\n        eval_set=[(Xtr[split_idx:], ytr_enc[split_idx:])],\n        verbose=False\n    )\n    acc_xgb, f1_xgb, yhat_main, ytrue_main = metrics_from_proba_encoded(xgb.predict_proba(Xte), yte_enc)\n    print(f\"  XGB regime-aware: {time.time()-t0:.1f}s\")\n\n    # Step 9: Compute regime-conditioned hit rates\n    hr_bal, hr_tox = regime_hits(yhat_main, ytrue_main, test['regime_hmm'].values)\n\n    # Step 10: Store results for this fold\n    results.append({\n        'fold': fold,\n        'test_start': te_s, \n        'test_end': te_e,\n        'acc_lr_base': acc_lr_base,   \n        'f1_lr_base': f1_lr_base,\n        'acc_xgb_base': acc_xgb_base, \n        'f1_xgb_base': f1_xgb_base,\n        'acc_lr': acc_lr,   \n        'f1_lr': f1_lr,\n        'acc_xgb': acc_xgb, \n        'f1_xgb': f1_xgb,\n        'hr_bal': hr_bal, \n        'hr_tox': hr_tox,\n        'lift': hr_tox - hr_bal,\n        'pct_toxic_test': float((test['regime_hmm'] == 1).mean())\n    })\n    \n    print(f\"  FOLD TOTAL: {time.time()-fold_start:.1f}s\")\n    fold += 1\n\n# Create results dataframe\ndf_res = pd.DataFrame(results)\nprint(\"\\n\" + \"=\"*60)\nprint(f\"EVALUATION COMPLETE: {len(df_res)} folds\")\nprint(\"=\"*60)\n\nif len(df_res) == 0:\n    raise RuntimeError(\"No folds evaluated. Check TRAIN_DAYS/TEST_HOURS/STRIDE_HRS parameters.\")\n\n# Display per-fold results\ncols = ['fold', 'test_start', 'test_end', 'acc_lr_base', 'acc_lr', 'acc_xgb_base', 'acc_xgb', 'hr_bal', 'hr_tox', 'lift', 'pct_toxic_test']\nprint(\"\\nPer-Fold Results:\")\ndisplay(df_res[cols].round(3))\n\n# Display average metrics across folds\nprint(\"\\nAverage Metrics Across Folds:\")\navg_metrics = df_res[['acc_lr_base', 'acc_lr', 'acc_xgb_base', 'acc_xgb', 'hr_bal', 'hr_tox', 'lift']].mean()\ndisplay(avg_metrics.round(3))"
  },
  {
   "cell_type": "markdown",
   "id": "f03ceb4f",
   "metadata": {},
   "source": "## 9. Results Visualization\n\nThis plot shows the **regime-conditioned hit rates** for each fold, which is the central result validating our hypothesis.\n\n### Interpretation:\n- **Blue bars (Balanced regime)**: Accuracy when HMM identifies balanced market conditions\n- **Orange bars (Toxic regime)**: Accuracy when HMM identifies toxic market conditions\n- **Lift (key metric)**: Difference between toxic and balanced hit rates\n\n### Expected Pattern:\nIf our hypothesis is correct, orange bars should be consistently higher than blue bars across most folds, indicating that **toxic regimes are more predictable** than balanced regimes."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7195d",
   "metadata": {},
   "outputs": [],
   "source": "# Create figure with adequate size\nfig, ax = plt.subplots(figsize=(10, 5))\n\n# Bar positions\nx = np.arange(len(df_res))\nwidth = 0.35\n\n# Plot bars\nbars1 = ax.bar(x - width/2, df_res['hr_bal'], width, label='Balanced Regime', alpha=0.8, color='#3498db')\nbars2 = ax.bar(x + width/2, df_res['hr_tox'], width, label='Toxic Regime', alpha=0.8, color='#e74c3c')\n\n# Formatting\nlabels = pd.to_datetime(df_res['test_start']).dt.strftime('%m-%d %H:%M')\nax.set_xticks(x)\nax.set_xticklabels(labels, rotation=45, ha='right')\nax.set_xlabel(\"Test Window Start Time\", fontsize=11)\nax.set_ylabel(\"Hit Rate (Accuracy)\", fontsize=11)\n\n# Calculate mean lift\nmean_lift = df_res['lift'].mean()\ntitle_color = 'green' if mean_lift > 0 else 'red'\nax.set_title(f\"Regime-Conditioned Hit Rate Across Folds\\nMean Lift = {mean_lift:.3f} ({mean_lift*100:.1f}%)\", \n             fontsize=12, fontweight='bold')\n\n# Add horizontal line at 50% (random guess baseline for BINARY classification)\nax.axhline(y=0.50, color='gray', linestyle='--', linewidth=1, alpha=0.5, label='Random Baseline (50%)')\n\n# Legend\nax.legend(loc='upper left', fontsize=10)\n\n# Grid for readability\nax.grid(axis='y', alpha=0.3, linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\n# Print summary statistics\nprint(\"\\nSummary Statistics:\")\nprint(f\"Mean Balanced Hit Rate: {df_res['hr_bal'].mean():.3f} ({df_res['hr_bal'].mean()*100:.1f}%)\")\nprint(f\"Mean Toxic Hit Rate:    {df_res['hr_tox'].mean():.3f} ({df_res['hr_tox'].mean()*100:.1f}%)\")\nprint(f\"Mean Lift:              {mean_lift:.3f} ({mean_lift*100:.1f}%)\")\nprint(f\"Random Baseline:        0.500 (50.0%)\")\nprint(f\"\\nHypothesis Validation: {'✓ SUPPORTED' if mean_lift > 0 else '✗ NOT SUPPORTED'}\")\nif mean_lift > 0:\n    print(f\"  → Toxic regimes are {mean_lift*100:.1f}% more predictable than balanced regimes\")\nelse:\n    print(f\"  → No evidence that toxic regimes are more predictable\")"
  },
  {
   "cell_type": "markdown",
   "id": "u278560ba",
   "source": "## 10. Baseline vs Regime-Aware Performance Comparison\n\nThis visualization compares model performance **with and without** regime information to quantify the value-add of the HMM regime discovery step.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "svm9ffbduqe",
   "source": "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# --- Left Plot: Logistic Regression ---\nax1 = axes[0]\nx = np.arange(len(df_res))\nwidth = 0.35\n\nbars1 = ax1.bar(x - width/2, df_res['acc_lr_base'], width, label='LR Baseline', alpha=0.8, color='#95a5a6')\nbars2 = ax1.bar(x + width/2, df_res['acc_lr'], width, label='LR + Regime', alpha=0.8, color='#3498db')\n\nax1.set_xlabel('Fold', fontsize=11)\nax1.set_ylabel('Accuracy', fontsize=11)\nax1.set_title(f'Logistic Regression\\nMean Improvement: {(df_res[\"acc_lr\"].mean() - df_res[\"acc_lr_base\"].mean())*100:.2f}%', \n              fontsize=12, fontweight='bold')\nax1.set_xticks(x)\nax1.set_xticklabels([f'F{i}' for i in df_res['fold']])\nax1.axhline(y=0.50, color='red', linestyle='--', linewidth=1, alpha=0.5, label='Random (50%)')\nax1.legend(fontsize=9)\nax1.grid(axis='y', alpha=0.3, linestyle='--')\n\n# --- Right Plot: XGBoost ---\nax2 = axes[1]\nbars3 = ax2.bar(x - width/2, df_res['acc_xgb_base'], width, label='XGB Baseline', alpha=0.8, color='#95a5a6')\nbars4 = ax2.bar(x + width/2, df_res['acc_xgb'], width, label='XGB + Regime', alpha=0.8, color='#e74c3c')\n\nax2.set_xlabel('Fold', fontsize=11)\nax2.set_ylabel('Accuracy', fontsize=11)\nax2.set_title(f'XGBoost\\nMean Improvement: {(df_res[\"acc_xgb\"].mean() - df_res[\"acc_xgb_base\"].mean())*100:.2f}%', \n              fontsize=12, fontweight='bold')\nax2.set_xticks(x)\nax2.set_xticklabels([f'F{i}' for i in df_res['fold']])\nax2.axhline(y=0.50, color='red', linestyle='--', linewidth=1, alpha=0.5, label='Random (50%)')\nax2.legend(fontsize=9)\nax2.grid(axis='y', alpha=0.3, linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\n# Print improvement statistics\nprint(\"\\nRegime-Awareness Performance Gains:\")\nprint(\"=\"*50)\nlr_improvement = (df_res['acc_lr'].mean() - df_res['acc_lr_base'].mean()) * 100\nxgb_improvement = (df_res['acc_xgb'].mean() - df_res['acc_xgb_base'].mean()) * 100\n\nprint(f\"Logistic Regression:\")\nprint(f\"  Baseline:      {df_res['acc_lr_base'].mean():.4f} ({df_res['acc_lr_base'].mean()*100:.2f}%)\")\nprint(f\"  + Regime:      {df_res['acc_lr'].mean():.4f} ({df_res['acc_lr'].mean()*100:.2f}%)\")\nprint(f\"  Improvement:   {lr_improvement:+.2f}%\")\nprint(f\"\\nXGBoost:\")\nprint(f\"  Baseline:      {df_res['acc_xgb_base'].mean():.4f} ({df_res['acc_xgb_base'].mean()*100:.2f}%)\")\nprint(f\"  + Regime:      {df_res['acc_xgb'].mean():.4f} ({df_res['acc_xgb'].mean()*100:.2f}%)\")\nprint(f\"  Improvement:   {xgb_improvement:+.2f}%\")\nprint(f\"\\nRandom Baseline: 50.00%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "m384c82xgx9",
   "source": "## 11. Feature Importance Analysis\n\nXGBoost tracks which features contribute most to prediction accuracy. This analysis reveals:\n1. Which PCA components are most predictive\n2. Whether the HMM regime feature is actually being used by the model\n3. Feature importance validation (confirms our feature engineering is meaningful)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "dkq3wqsxi65",
   "source": "# Train a final model for feature importance analysis\nprint(\"Training final XGBoost model on all data for feature importance analysis...\")\n\n# Use all labeled data\ndf_all = df_lbl.dropna(subset=['y']).copy()\n\n# Take a sample to keep training time reasonable\nsample_size = min(200000, len(df_all))\ndf_sample = df_all.sample(n=sample_size, random_state=RANDOM_STATE)\n\n# Split 80/20 for train/val\nsplit_idx = int(0.8 * len(df_sample))\ndf_train_full = df_sample.iloc[:split_idx]\ndf_val_full = df_sample.iloc[split_idx:]\n\n# Scale and PCA\nXtr, Xval, pca = scale_features(df_train_full, df_val_full)\n\n# Fit HMM\nhmm_full, tox_state_full = fit_hmm(Xtr, df_train_full, n_states=2)\n\n# Predict regimes\ns_tr = hmm_full.predict(Xtr)\ns_val = hmm_full.predict(Xval)\n\ndf_train_full['regime_hmm'] = (s_tr == tox_state_full).astype(int)\ndf_val_full['regime_hmm'] = (s_val == tox_state_full).astype(int)\n\n# Augment with regime\nXtr_regime = np.c_[Xtr, df_train_full['regime_hmm'].values]\nXval_regime = np.c_[Xval, df_val_full['regime_hmm'].values]\n\n# Encode labels (binary)\nytr = np.array([ENC_MAP[v] for v in df_train_full['y'].values])\nyval = np.array([ENC_MAP[v] for v in df_val_full['y'].values])\n\n# Train regime-aware XGBoost (BINARY)\nw = compute_sample_weight(class_weight='balanced', y=ytr)\nxgb_final = XGBClassifier(\n    n_estimators=XGB_N_ESTIMATORS,\n    max_depth=XGB_MAX_DEPTH,\n    learning_rate=XGB_LEARNING_RATE,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    objective='binary:logistic',  # Binary classification\n    tree_method='hist',\n    reg_lambda=1.0,\n    random_state=RANDOM_STATE,\n    early_stopping_rounds=XGB_EARLY_STOPPING\n)\n\nxgb_final.fit(\n    Xtr_regime, ytr,\n    sample_weight=w,\n    eval_set=[(Xval_regime, yval)],\n    verbose=False\n)\n\n# Extract feature importance\nfeature_importance = xgb_final.feature_importances_\n\n# Create feature names (PCA components + regime)\nn_pca_components = Xtr.shape[1]\nfeature_names = [f'PC{i+1}' for i in range(n_pca_components)] + ['Regime']\n\n# Sort by importance\nimportance_df = pd.DataFrame({\n    'Feature': feature_names,\n    'Importance': feature_importance\n}).sort_values('Importance', ascending=False)\n\n# Plot\nfig, ax = plt.subplots(figsize=(10, 6))\ncolors = ['#e74c3c' if f == 'Regime' else '#3498db' for f in importance_df['Feature']]\nbars = ax.barh(importance_df['Feature'], importance_df['Importance'], color=colors, alpha=0.8)\n\nax.set_xlabel('Importance (Gain)', fontsize=11)\nax.set_ylabel('Feature', fontsize=11)\nax.set_title('XGBoost Feature Importance (Regime-Aware Model, Binary Classification)', fontsize=12, fontweight='bold')\nax.grid(axis='x', alpha=0.3, linestyle='--')\nax.invert_yaxis()\n\nplt.tight_layout()\nplt.show()\n\n# Print importance values\nprint(\"\\nFeature Importance Rankings:\")\nprint(\"=\"*50)\nfor idx, row in importance_df.iterrows():\n    pct = row['Importance'] / feature_importance.sum() * 100\n    marker = \" ⭐\" if row['Feature'] == 'Regime' else \"\"\n    print(f\"{row['Feature']:10s}: {row['Importance']:.4f} ({pct:5.2f}%){marker}\")\n\nregime_importance = importance_df[importance_df['Feature'] == 'Regime']['Importance'].values[0]\nregime_pct = regime_importance / feature_importance.sum() * 100\n\nprint(f\"\\n{'='*50}\")\nprint(f\"Regime Feature Contribution: {regime_pct:.2f}%\")\nif regime_pct > 10:\n    print(\"✓ Regime is a STRONG predictor (>10% importance)\")\nelif regime_pct > 5:\n    print(\"✓ Regime is a MODERATE predictor (5-10% importance)\")\nelse:\n    print(\"⚠ Regime has LOW importance (<5%) - may not be adding much value\")\n    \nprint(f\"\\nNumber of PCA components: {n_pca_components}\")\nprint(f\"Variance explained: {PCA_VARIANCE*100}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}